{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "martial-bumper",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-03T13:57:05.857484Z",
     "iopub.status.busy": "2021-06-03T13:57:05.855171Z",
     "iopub.status.idle": "2021-06-03T13:57:07.308997Z",
     "shell.execute_reply": "2021-06-03T13:57:07.304023Z",
     "shell.execute_reply.started": "2021-06-03T12:00:15.330106Z"
    },
    "papermill": {
     "duration": 1.490685,
     "end_time": "2021-06-03T13:57:07.309322",
     "exception": false,
     "start_time": "2021-06-03T13:57:05.818637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "training_dir = '../input/snu-2021-1-ds-project-3/train'\n",
    "test_dir = '../input/snu-2021-1-ds-project-3/test'\n",
    "\n",
    "def extract_age(info_file):\n",
    "    '''\n",
    "        info file(###.txt)로부터 나이 정보를 뽑아냅니다.\n",
    "    '''\n",
    "    with open(info_file, 'r') as f:\n",
    "        info = f.read()\n",
    "        for i, line in enumerate(info.split(\"\\n\")):\n",
    "            if line.startswith(\"#Age\"):\n",
    "                age = float(line.split(\": \")[1].strip())\n",
    "    return age\n",
    "\n",
    "def extract_sex(info_file):\n",
    "    '''\n",
    "        info file(###.txt)로부터 성별 정보를 뽑아냅니다.\n",
    "    '''\n",
    "    with open(info_file, 'r') as f:\n",
    "            info = f.read()\n",
    "            for i, line in enumerate(info.split(\"\\n\")):\n",
    "                if line.startswith(\"#Sex\"):\n",
    "                    sex = line.split(\": \")[1].strip()\n",
    "    return sex\n",
    "\n",
    "def extract_labels(info_file):\n",
    "    '''\n",
    "        info file(###.txt)로부터 label(들) 정보를 뽑아냅니다.\n",
    "    '''\n",
    "    with open(info_file, 'r') as f:\n",
    "            info = f.read()\n",
    "            for i, line in enumerate(info.split(\"\\n\")):\n",
    "                if line.startswith(\"#Dx\"):\n",
    "                    labels = line.split(\": \")[1].strip()\n",
    "                    labels = labels.split()\n",
    "    return labels\n",
    "\n",
    "def read_files(data_directory, is_training=True):\n",
    "    '''\n",
    "        data directory(train 또는 test)로부터 모든 sample들의\n",
    "        id, age, sex, recording, labels 정보를 읽어들여\n",
    "        (id, age, sex, recording, labels)의 list를 반환합니다.\n",
    "        is_training=False일 경우엔 labels 정보를 읽어들이지 않습니다.\n",
    "    '''\n",
    "    list_id = []\n",
    "    list_age = []\n",
    "    list_sex = []\n",
    "    list_recording = []\n",
    "    list_labels = []\n",
    "    for f in os.listdir(data_directory):\n",
    "        root, extension = os.path.splitext(f)\n",
    "        if not root.startswith(\".\") and extension == \".txt\":\n",
    "            list_id.append(int(root))\n",
    "            info_file = os.path.join(data_directory, root + \".txt\")\n",
    "            recording_file = os.path.join(data_directory, root + \".npy\")\n",
    "            age = extract_age(info_file)\n",
    "            list_age.append(age)\n",
    "            sex = extract_sex(info_file)\n",
    "            list_sex.append(sex)\n",
    "            with open(recording_file, 'rb') as g:\n",
    "                recording = np.load(g)\n",
    "                list_recording.append(recording)\n",
    "            if is_training:\n",
    "                labels = extract_labels(info_file)\n",
    "                list_labels.append(labels)\n",
    "    if is_training:\n",
    "        return list(zip(list_id, list_age, list_sex, list_recording, list_labels))\n",
    "    else:\n",
    "        return list(zip(list_id, list_age, list_sex, list_recording))\n",
    "    \n",
    "class Dataset_ECG(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        Build ECG dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, num_classes=12):\n",
    "        \"\"\"\n",
    "            dataset을 읽어들여 id, age, sex, recording, labels를 저장한 list를 만들어 줍니다.\n",
    "        \"\"\"\n",
    "        self.sample_id = []\n",
    "        self.sample_age = []\n",
    "        self.sample_sex = []\n",
    "        self.sample_recording = []\n",
    "        self.sample_labels = []\n",
    "        self.num_samples = len(dataset)\n",
    "        \n",
    "        for idx in range(self.num_samples):\n",
    "            _id, _age, _sex, _recording, _labels = dataset[idx]\n",
    "            \n",
    "            # model에 input으로 들어가는 data는 torch.Tensor 타입으로 변환해 줍니다.\n",
    "            age = torch.tensor(_age)\n",
    "            sex = torch.tensor(0) if _sex == \"F\" else torch.tensor(1)\n",
    "            #여자면 0, 남자면 1\n",
    "            \n",
    "            recording = torch.tensor(_recording)\n",
    "            labels = torch.tensor(np.zeros(num_classes))\n",
    "            \n",
    "            for label in _labels:\n",
    "                labels[int(label)] = 1\n",
    "            #원 핫 인코딩으로 분류\n",
    "            \n",
    "            \n",
    "            self.sample_id.append(_id)\n",
    "            self.sample_age.append(age)\n",
    "            self.sample_sex.append(sex)\n",
    "            self.sample_recording.append(recording)\n",
    "            self.sample_labels.append(labels)\n",
    "\n",
    "        print(f'Loaded {self.num_samples} samples...')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"id\": self.sample_id[idx],\n",
    "            \"age\": self.sample_age[idx],\n",
    "            \"sex\": self.sample_sex[idx],\n",
    "            \"recording\": self.sample_recording[idx],\n",
    "            \"labels\": self.sample_labels[idx]\n",
    "        }\n",
    "\n",
    "\n",
    "#num_classes -> label / num_leads -> recording1,2 / out_channel -> recording shape\n",
    "class Example_CNN_v1(torch.nn.Module):\n",
    "    def __init__(self, num_classes=12, num_leads=2):\n",
    "        super(Example_CNN_v1, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_leads = num_leads\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=self.num_leads, out_channels=32, kernel_size=15, stride=3, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv1d(in_channels=32, out_channels=64, kernel_size=13, stride=3, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=64, out_channels=128, kernel_size=10, stride=2)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.conv4 = torch.nn.Conv1d(in_channels=128, out_channels=64, kernel_size=8, stride=2)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.conv5 = torch.nn.Conv1d(in_channels=64, out_channels=32, kernel_size=7, stride=2)\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(32*64, 128)\n",
    "        self.relu6 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(128, self.num_classes)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이 모델은 recording만을 input으로 받습니다. feature를 추가적으로 사용하도록 할 수도 있습니다.\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.flatten(x)\n",
    "        out = self.sigmoid(x)\n",
    "        return out\n",
    "\n",
    "print(\"완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "signed-clause",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:57:07.448996Z",
     "iopub.status.busy": "2021-06-03T13:57:07.447927Z",
     "iopub.status.idle": "2021-06-03T13:57:07.478402Z",
     "shell.execute_reply": "2021-06-03T13:57:07.479871Z",
     "shell.execute_reply.started": "2021-06-03T12:00:25.660152Z"
    },
    "papermill": {
     "duration": 0.115476,
     "end_time": "2021-06-03T13:57:07.480124",
     "exception": false,
     "start_time": "2021-06-03T13:57:07.364648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Example_CNN_v2(torch.nn.Module):\n",
    "    def __init__(self, num_classes=12, num_leads=2):\n",
    "        super(Example_CNN_v2, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_leads = num_leads\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=self.num_leads, out_channels=32, kernel_size=15, stride=3, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.batch1 = torch.nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv1d(in_channels=32, out_channels=64, kernel_size=13, stride=3, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.batch2 = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        \n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=64, out_channels=128, kernel_size=10, stride=2)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.batch3 = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv4 = torch.nn.Conv1d(in_channels=128, out_channels=128, kernel_size=8, stride=2)\n",
    "        self.relu4 = torch.nn.ReLU()\n",
    "        self.batch4 = torch.nn.BatchNorm1d(128)\n",
    "                                             \n",
    "        self.conv5 = torch.nn.Conv1d(in_channels=128, out_channels=256, kernel_size=7, stride=2)\n",
    "        self.relu5 = torch.nn.ReLU()\n",
    "        self.batch5 = torch.nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.conv6 = torch.nn.Conv1d(in_channels=256, out_channels=128, kernel_size=7, stride=2)\n",
    "        self.relu6 = torch.nn.ReLU()\n",
    "        self.batch6 = torch.nn.BatchNorm1d(128)\n",
    "        \n",
    "        self.conv7 = torch.nn.Conv1d(in_channels=128, out_channels=64, kernel_size=6, stride=2)\n",
    "        self.relu7 = torch.nn.ReLU()\n",
    "        self.batch7 = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv8 = torch.nn.Conv1d(in_channels=64, out_channels=32, kernel_size=6, stride=2)\n",
    "        self.relu8 = torch.nn.ReLU()\n",
    "        self.batch8 = torch.nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv9 = torch.nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, stride=2)\n",
    "        self.relu9 = torch.nn.ReLU()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(32*4, 256)\n",
    "        self.relu_fc = torch.nn.ReLU()\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 64)\n",
    "        self.fc4 = torch.nn.Linear(64, 32)\n",
    "        self.fc5 = torch.nn.Linear(32, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이 모델은 recording만을 input으로 받습니다. feature를 추가적으로 사용하도록 할 수도 있습니다.\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.batch4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.batch5(x)\n",
    "    \n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.batch6(x)\n",
    "        \n",
    "        x = self.conv7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.batch7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.relu8(x)\n",
    "        x = self.batch8(x)\n",
    "\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_fc(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_fc(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_fc(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_fc(x)\n",
    "        \n",
    "        out = self.fc5(x)\n",
    "       \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tropical-samoa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T13:57:07.604801Z",
     "iopub.status.busy": "2021-06-03T13:57:07.603650Z",
     "iopub.status.idle": "2021-06-03T14:01:33.869826Z",
     "shell.execute_reply": "2021-06-03T14:01:33.870645Z",
     "shell.execute_reply.started": "2021-06-03T12:00:30.248531Z"
    },
    "papermill": {
     "duration": 266.331151,
     "end_time": "2021-06-03T14:01:33.870933",
     "exception": false,
     "start_time": "2021-06-03T13:57:07.539782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total training samples: 19212\n",
      "Number of training samples: 19212\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "total_training_set = sorted(read_files(training_dir), key=lambda sample: sample[0])\n",
    "total_num_training = len(total_training_set)\n",
    "print(f\"Number of total training samples: {total_num_training}\")\n",
    "\n",
    "#num_validation = int(total_num_training * 0.2)\n",
    "#num_training = total_num_training - num_validation\n",
    "num_training = total_num_training\n",
    "#validation_set = total_training_set[:num_validation]\n",
    "#training_set = total_training_set[num_validation:]\n",
    "training_set = total_training_set#\n",
    "#print(f'Number of validation samples: {num_validation}')\n",
    "print(f'Number of training samples: {num_training}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "animal-absolute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:01:33.987276Z",
     "iopub.status.busy": "2021-06-03T14:01:33.985633Z",
     "iopub.status.idle": "2021-06-03T14:01:33.990783Z",
     "shell.execute_reply": "2021-06-03T14:01:33.991375Z",
     "shell.execute_reply.started": "2021-06-03T12:03:56.575976Z"
    },
    "papermill": {
     "duration": 0.088386,
     "end_time": "2021-06-03T14:01:33.991553",
     "exception": false,
     "start_time": "2021-06-03T14:01:33.903167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dated-stationery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:01:34.063628Z",
     "iopub.status.busy": "2021-06-03T14:01:34.062897Z",
     "iopub.status.idle": "2021-06-03T14:01:35.911822Z",
     "shell.execute_reply": "2021-06-03T14:01:35.912407Z",
     "shell.execute_reply.started": "2021-06-03T12:03:56.651658Z"
    },
    "papermill": {
     "duration": 1.889541,
     "end_time": "2021-06-03T14:01:35.912590",
     "exception": false,
     "start_time": "2021-06-03T14:01:34.023049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 19212 samples...\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "training_dataset = Dataset_ECG(training_set, num_classes=12)\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fiscal-landscape",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:01:35.994097Z",
     "iopub.status.busy": "2021-06-03T14:01:35.993249Z",
     "iopub.status.idle": "2021-06-03T14:18:11.747987Z",
     "shell.execute_reply": "2021-06-03T14:18:11.748628Z",
     "shell.execute_reply.started": "2021-06-03T12:09:06.629398Z"
    },
    "papermill": {
     "duration": 995.804555,
     "end_time": "2021-06-03T14:18:11.748813",
     "exception": false,
     "start_time": "2021-06-03T14:01:35.944258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n",
      "training loss of epoch 1: 0.2507011435826544\n",
      "\n",
      "***** Epoch 2 *****\n",
      "training loss of epoch 2: 0.19691715932755727\n",
      "\n",
      "***** Epoch 3 *****\n",
      "training loss of epoch 3: 0.18163216320453007\n",
      "\n",
      "***** Epoch 4 *****\n",
      "training loss of epoch 4: 0.16973982069067656\n",
      "\n",
      "***** Epoch 5 *****\n",
      "training loss of epoch 5: 0.16066806130067782\n",
      "\n",
      "***** Epoch 6 *****\n",
      "training loss of epoch 6: 0.15281839563584418\n",
      "\n",
      "***** Epoch 7 *****\n",
      "training loss of epoch 7: 0.14658229929146452\n",
      "\n",
      "***** Epoch 8 *****\n",
      "training loss of epoch 8: 0.1397230401285928\n",
      "\n",
      "***** Epoch 9 *****\n",
      "training loss of epoch 9: 0.13318993072178478\n",
      "\n",
      "***** Epoch 10 *****\n",
      "training loss of epoch 10: 0.1266883983988548\n",
      "\n",
      "***** Epoch 11 *****\n",
      "training loss of epoch 11: 0.12011686464083242\n",
      "\n",
      "***** Epoch 12 *****\n",
      "training loss of epoch 12: 0.11241597621271592\n",
      "\n",
      "***** Epoch 13 *****\n",
      "training loss of epoch 13: 0.1047648793599527\n",
      "\n",
      "***** Epoch 14 *****\n",
      "training loss of epoch 14: 0.09760419131000317\n",
      "\n",
      "***** Epoch 15 *****\n",
      "training loss of epoch 15: 0.09121039822408379\n",
      "\n",
      "***** Epoch 16 *****\n",
      "training loss of epoch 16: 0.08450875160371446\n",
      "\n",
      "***** Epoch 17 *****\n",
      "training loss of epoch 17: 0.07853356538529785\n",
      "\n",
      "***** Epoch 18 *****\n",
      "training loss of epoch 18: 0.07127308973893647\n",
      "\n",
      "***** Epoch 19 *****\n",
      "training loss of epoch 19: 0.06617068811235528\n",
      "\n",
      "***** Epoch 20 *****\n",
      "training loss of epoch 20: 0.0634550833086063\n",
      "\n",
      "***** Epoch 21 *****\n",
      "training loss of epoch 21: 0.0589133122100832\n",
      "\n",
      "***** Epoch 22 *****\n",
      "training loss of epoch 22: 0.053792978686668914\n",
      "\n",
      "***** Epoch 23 *****\n",
      "training loss of epoch 23: 0.05094521658015294\n",
      "\n",
      "***** Epoch 24 *****\n",
      "training loss of epoch 24: 0.049546208325555605\n",
      "\n",
      "***** Epoch 25 *****\n",
      "training loss of epoch 25: 0.045839702253568294\n",
      "\n",
      "***** Epoch 26 *****\n",
      "training loss of epoch 26: 0.04229706076212249\n",
      "\n",
      "***** Epoch 27 *****\n",
      "training loss of epoch 27: 0.040503941340629596\n",
      "\n",
      "***** Epoch 28 *****\n",
      "training loss of epoch 28: 0.04037982776140375\n",
      "\n",
      "***** Epoch 29 *****\n",
      "training loss of epoch 29: 0.03587492784134837\n",
      "\n",
      "***** Epoch 30 *****\n",
      "training loss of epoch 30: 0.03507377247038639\n",
      "\n",
      "***** Epoch 31 *****\n",
      "training loss of epoch 31: 0.033847236033886\n",
      "\n",
      "***** Epoch 32 *****\n",
      "training loss of epoch 32: 0.03200407686047239\n",
      "\n",
      "***** Epoch 33 *****\n",
      "training loss of epoch 33: 0.0301026337682608\n",
      "\n",
      "***** Epoch 34 *****\n",
      "training loss of epoch 34: 0.029195070065258254\n",
      "\n",
      "***** Epoch 35 *****\n",
      "training loss of epoch 35: 0.02813424079242984\n",
      "\n",
      "***** Epoch 36 *****\n",
      "training loss of epoch 36: 0.02784944870187969\n",
      "\n",
      "***** Epoch 37 *****\n",
      "training loss of epoch 37: 0.024971807529010005\n",
      "\n",
      "***** Epoch 38 *****\n",
      "training loss of epoch 38: 0.02447826926416162\n",
      "\n",
      "***** Epoch 39 *****\n",
      "training loss of epoch 39: 0.023601496724426532\n",
      "\n",
      "***** Epoch 40 *****\n",
      "training loss of epoch 40: 0.02174674297673765\n",
      "\n",
      "***** Epoch 41 *****\n",
      "training loss of epoch 41: 0.02224283190312655\n",
      "\n",
      "***** Epoch 42 *****\n",
      "training loss of epoch 42: 0.02284645928494598\n",
      "\n",
      "***** Epoch 43 *****\n",
      "training loss of epoch 43: 0.021316863386387285\n",
      "\n",
      "***** Epoch 44 *****\n",
      "training loss of epoch 44: 0.020247467820861963\n",
      "\n",
      "***** Epoch 45 *****\n",
      "training loss of epoch 45: 0.018241983110306014\n",
      "\n",
      "***** Epoch 46 *****\n",
      "training loss of epoch 46: 0.018300483103588925\n",
      "\n",
      "***** Epoch 47 *****\n",
      "training loss of epoch 47: 0.01898796830206029\n",
      "\n",
      "***** Epoch 48 *****\n",
      "training loss of epoch 48: 0.018742475500765295\n",
      "\n",
      "***** Epoch 49 *****\n",
      "training loss of epoch 49: 0.016426232675809768\n",
      "\n",
      "***** Epoch 50 *****\n",
      "training loss of epoch 50: 0.015107586121425093\n",
      "\n",
      "***** Epoch 51 *****\n",
      "training loss of epoch 51: 0.016471481278278494\n",
      "\n",
      "***** Epoch 52 *****\n",
      "training loss of epoch 52: 0.015464632300960028\n",
      "\n",
      "***** Epoch 53 *****\n",
      "training loss of epoch 53: 0.01422665786298175\n",
      "\n",
      "***** Epoch 54 *****\n",
      "training loss of epoch 54: 0.015146996083024306\n",
      "\n",
      "***** Epoch 55 *****\n",
      "training loss of epoch 55: 0.013667526441325668\n",
      "\n",
      "***** Epoch 56 *****\n",
      "training loss of epoch 56: 0.01424813997738915\n",
      "\n",
      "***** Epoch 57 *****\n",
      "training loss of epoch 57: 0.01446533252251248\n",
      "\n",
      "***** Epoch 58 *****\n",
      "training loss of epoch 58: 0.012646121415894144\n",
      "\n",
      "***** Epoch 59 *****\n",
      "training loss of epoch 59: 0.012646211021340463\n",
      "\n",
      "***** Epoch 60 *****\n",
      "training loss of epoch 60: 0.011890244128563624\n",
      "\n",
      "***** Epoch 61 *****\n",
      "training loss of epoch 61: 0.012382032215491112\n",
      "\n",
      "***** Epoch 62 *****\n",
      "training loss of epoch 62: 0.012719569527712887\n",
      "\n",
      "***** Epoch 63 *****\n",
      "training loss of epoch 63: 0.01102673259590144\n",
      "\n",
      "***** Epoch 64 *****\n",
      "training loss of epoch 64: 0.011671647777222398\n",
      "\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, pin_memory=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "model3 = Example_CNN_v2(num_classes=12, num_leads=2)\n",
    "\n",
    "model3.to(device)\n",
    "model3.train()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # for multi-label classification\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'***** Epoch {epoch} *****')\n",
    "    epoch_training_loss_sum = 0.0\n",
    "    for i_batch, sample_batched in enumerate(training_loader):\n",
    "        b_recording = sample_batched[\"recording\"].to(device)\n",
    "        b_labels = sample_batched[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        b_out = model3(b_recording)\n",
    "        loss = criterion(b_out, b_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_loss_sum += loss.item() * b_labels.shape[0]\n",
    "\n",
    "    epoch_training_loss = epoch_training_loss_sum / num_training\n",
    "    print(f'training loss of epoch {epoch}: {epoch_training_loss}\\n')\n",
    "\n",
    "print(\"완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worthy-effects",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:18:11.859078Z",
     "iopub.status.busy": "2021-06-03T14:18:11.858258Z",
     "iopub.status.idle": "2021-06-03T14:18:13.352120Z",
     "shell.execute_reply": "2021-06-03T14:18:13.351493Z",
     "shell.execute_reply.started": "2021-06-03T12:11:17.194398Z"
    },
    "papermill": {
     "duration": 1.552541,
     "end_time": "2021-06-03T14:18:13.352280",
     "exception": false,
     "start_time": "2021-06-03T14:18:11.799739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12836\n",
      "6376\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idx_set = [[], []]\n",
    "\n",
    "idx = [i for i in range(len(training_dataset)) if training_dataset[i][\"labels\"][8]==1]\n",
    "idx_set[0] = idx\n",
    "idx = [i for i in range(len(training_dataset)) if training_dataset[i][\"labels\"][8]==0]\n",
    "idx_set[1] = idx\n",
    "    \n",
    "\n",
    "print(len(idx_set[0]))\n",
    "print(len(idx_set[1]))\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "damaged-northwest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:18:13.467181Z",
     "iopub.status.busy": "2021-06-03T14:18:13.466307Z",
     "iopub.status.idle": "2021-06-03T14:18:13.471448Z",
     "shell.execute_reply": "2021-06-03T14:18:13.470914Z",
     "shell.execute_reply.started": "2021-06-03T12:11:17.900817Z"
    },
    "papermill": {
     "duration": 0.064569,
     "end_time": "2021-06-03T14:18:13.471572",
     "exception": false,
     "start_time": "2021-06-03T14:18:13.407003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6376\n"
     ]
    }
   ],
   "source": [
    "abnormal_train_set = []\n",
    "for i in idx_set[1] :\n",
    "    abnormal_train_set.append(training_set[i])\n",
    "print(len(abnormal_train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "defensive-rhythm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:18:13.582564Z",
     "iopub.status.busy": "2021-06-03T14:18:13.581910Z",
     "iopub.status.idle": "2021-06-03T14:18:14.313361Z",
     "shell.execute_reply": "2021-06-03T14:18:14.312742Z",
     "shell.execute_reply.started": "2021-06-03T12:11:17.910442Z"
    },
    "papermill": {
     "duration": 0.788788,
     "end_time": "2021-06-03T14:18:14.313554",
     "exception": false,
     "start_time": "2021-06-03T14:18:13.524766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6376 samples...\n"
     ]
    }
   ],
   "source": [
    "abnormal_training_dataset = Dataset_ECG(abnormal_train_set, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reliable-distribution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:18:14.435960Z",
     "iopub.status.busy": "2021-06-03T14:18:14.434886Z",
     "iopub.status.idle": "2021-06-03T14:18:14.459261Z",
     "shell.execute_reply": "2021-06-03T14:18:14.460256Z",
     "shell.execute_reply.started": "2021-06-03T12:11:18.423401Z"
    },
    "papermill": {
     "duration": 0.086743,
     "end_time": "2021-06-03T14:18:14.460482",
     "exception": false,
     "start_time": "2021-06-03T14:18:14.373739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(abnormal_training_dataset, pin_memory=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "model2 = Example_CNN_v2(num_classes=12, num_leads=2)\n",
    "\n",
    "model2.to(device)\n",
    "model2.train()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # for multi-label classification\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-sally",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:18:14.576603Z",
     "iopub.status.busy": "2021-06-03T14:18:14.575323Z",
     "iopub.status.idle": "2021-06-03T14:23:45.806786Z",
     "shell.execute_reply": "2021-06-03T14:23:45.807719Z",
     "shell.execute_reply.started": "2021-06-03T12:11:18.450204Z"
    },
    "papermill": {
     "duration": 331.29318,
     "end_time": "2021-06-03T14:23:45.807960",
     "exception": false,
     "start_time": "2021-06-03T14:18:14.514780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n",
      "training loss of epoch 1: 0.36978485797066685\n",
      "\n",
      "***** Epoch 2 *****\n",
      "training loss of epoch 2: 0.26933320135299743\n",
      "\n",
      "***** Epoch 3 *****\n",
      "training loss of epoch 3: 0.24717542348128238\n",
      "\n",
      "***** Epoch 4 *****\n",
      "training loss of epoch 4: 0.23284003305468137\n",
      "\n",
      "***** Epoch 5 *****\n",
      "training loss of epoch 5: 0.22502387241549207\n",
      "\n",
      "***** Epoch 6 *****\n",
      "training loss of epoch 6: 0.21746177730256683\n",
      "\n",
      "***** Epoch 7 *****\n",
      "training loss of epoch 7: 0.21004485032944478\n",
      "\n",
      "***** Epoch 8 *****\n",
      "training loss of epoch 8: 0.201786508777551\n",
      "\n",
      "***** Epoch 9 *****\n",
      "training loss of epoch 9: 0.19422492597579227\n",
      "\n",
      "***** Epoch 10 *****\n",
      "training loss of epoch 10: 0.18562438125453323\n",
      "\n",
      "***** Epoch 11 *****\n",
      "training loss of epoch 11: 0.17946087014117074\n",
      "\n",
      "***** Epoch 12 *****\n",
      "training loss of epoch 12: 0.1707531334441582\n",
      "\n",
      "***** Epoch 13 *****\n",
      "training loss of epoch 13: 0.16582388535208703\n",
      "\n",
      "***** Epoch 14 *****\n",
      "training loss of epoch 14: 0.15530063897117707\n",
      "\n",
      "***** Epoch 15 *****\n",
      "training loss of epoch 15: 0.14543018922239997\n",
      "\n",
      "***** Epoch 16 *****\n",
      "training loss of epoch 16: 0.13545517165140242\n",
      "\n",
      "***** Epoch 17 *****\n",
      "training loss of epoch 17: 0.13020065685973908\n",
      "\n",
      "***** Epoch 18 *****\n",
      "training loss of epoch 18: 0.12026011157059437\n",
      "\n",
      "***** Epoch 19 *****\n",
      "training loss of epoch 19: 0.11299112100534739\n",
      "\n",
      "***** Epoch 20 *****\n",
      "training loss of epoch 20: 0.10754638641901604\n",
      "\n",
      "***** Epoch 21 *****\n",
      "training loss of epoch 21: 0.09984083264865239\n",
      "\n",
      "***** Epoch 22 *****\n",
      "training loss of epoch 22: 0.09363883644496462\n",
      "\n",
      "***** Epoch 23 *****\n",
      "training loss of epoch 23: 0.08619714160375204\n",
      "\n",
      "***** Epoch 24 *****\n",
      "training loss of epoch 24: 0.07693343615945829\n",
      "\n",
      "***** Epoch 25 *****\n",
      "training loss of epoch 25: 0.07388779708671397\n",
      "\n",
      "***** Epoch 26 *****\n",
      "training loss of epoch 26: 0.06887816118339174\n",
      "\n",
      "***** Epoch 27 *****\n",
      "training loss of epoch 27: 0.06414424733601784\n",
      "\n",
      "***** Epoch 28 *****\n",
      "training loss of epoch 28: 0.055321067401881516\n",
      "\n",
      "***** Epoch 29 *****\n",
      "training loss of epoch 29: 0.05295630342083189\n",
      "\n",
      "***** Epoch 30 *****\n",
      "training loss of epoch 30: 0.053200925475480346\n",
      "\n",
      "***** Epoch 31 *****\n",
      "training loss of epoch 31: 0.04812780835735751\n",
      "\n",
      "***** Epoch 32 *****\n",
      "training loss of epoch 32: 0.04105708930613949\n",
      "\n",
      "***** Epoch 33 *****\n",
      "training loss of epoch 33: 0.03644837433091902\n",
      "\n",
      "***** Epoch 34 *****\n",
      "training loss of epoch 34: 0.035631835542578746\n",
      "\n",
      "***** Epoch 35 *****\n",
      "training loss of epoch 35: 0.03697217482775128\n",
      "\n",
      "***** Epoch 36 *****\n",
      "training loss of epoch 36: 0.03197548113203785\n",
      "\n",
      "***** Epoch 37 *****\n",
      "training loss of epoch 37: 0.03281650092109614\n",
      "\n",
      "***** Epoch 38 *****\n",
      "training loss of epoch 38: 0.029821694375179737\n",
      "\n",
      "***** Epoch 39 *****\n",
      "training loss of epoch 39: 0.028025364679521363\n",
      "\n",
      "***** Epoch 40 *****\n",
      "training loss of epoch 40: 0.027029516049914357\n",
      "\n",
      "***** Epoch 41 *****\n",
      "training loss of epoch 41: 0.025921183396769264\n",
      "\n",
      "***** Epoch 42 *****\n",
      "training loss of epoch 42: 0.02237693623289012\n",
      "\n",
      "***** Epoch 43 *****\n",
      "training loss of epoch 43: 0.02103730736152289\n",
      "\n",
      "***** Epoch 44 *****\n",
      "training loss of epoch 44: 0.02231653309273696\n",
      "\n",
      "***** Epoch 45 *****\n",
      "training loss of epoch 45: 0.020234211182212386\n",
      "\n",
      "***** Epoch 46 *****\n",
      "training loss of epoch 46: 0.022639816717385824\n",
      "\n",
      "***** Epoch 47 *****\n",
      "training loss of epoch 47: 0.02319664550104285\n",
      "\n",
      "***** Epoch 48 *****\n",
      "training loss of epoch 48: 0.02030009037174927\n",
      "\n",
      "***** Epoch 49 *****\n",
      "training loss of epoch 49: 0.01369274918746375\n",
      "\n",
      "***** Epoch 50 *****\n",
      "training loss of epoch 50: 0.012311934584623506\n",
      "\n",
      "***** Epoch 51 *****\n",
      "training loss of epoch 51: 0.012843822890615995\n",
      "\n",
      "***** Epoch 52 *****\n",
      "training loss of epoch 52: 0.018764281478112908\n",
      "\n",
      "***** Epoch 53 *****\n",
      "training loss of epoch 53: 0.0224715370136003\n",
      "\n",
      "***** Epoch 54 *****\n",
      "training loss of epoch 54: 0.02193465808015558\n",
      "\n",
      "***** Epoch 55 *****\n",
      "training loss of epoch 55: 0.014030180747054477\n",
      "\n",
      "***** Epoch 56 *****\n",
      "training loss of epoch 56: 0.012387525246097446\n",
      "\n",
      "***** Epoch 57 *****\n",
      "training loss of epoch 57: 0.013067396499642758\n",
      "\n",
      "***** Epoch 58 *****\n",
      "training loss of epoch 58: 0.011616913441754707\n",
      "\n",
      "***** Epoch 59 *****\n",
      "training loss of epoch 59: 0.009991644249098219\n",
      "\n",
      "***** Epoch 60 *****\n",
      "training loss of epoch 60: 0.010032314069924454\n",
      "\n",
      "***** Epoch 61 *****\n",
      "training loss of epoch 61: 0.012544048955097878\n",
      "\n",
      "***** Epoch 62 *****\n",
      "training loss of epoch 62: 0.012500245500346466\n",
      "\n",
      "***** Epoch 63 *****\n",
      "training loss of epoch 63: 0.013221554796225598\n",
      "\n",
      "***** Epoch 64 *****\n",
      "training loss of epoch 64: 0.012139260919860437\n",
      "\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'***** Epoch {epoch} *****')\n",
    "    epoch_training_loss_sum = 0.0\n",
    "    for i_batch, sample_batched in enumerate(training_loader):\n",
    "        b_recording = sample_batched[\"recording\"].to(device)\n",
    "        b_labels = sample_batched[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        b_out = model2(b_recording)\n",
    "        loss = criterion(b_out, b_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_loss_sum += loss.item() * b_labels.shape[0]\n",
    "\n",
    "    epoch_training_loss = epoch_training_loss_sum / len(abnormal_training_dataset)\n",
    "    print(f'training loss of epoch {epoch}: {epoch_training_loss}\\n')\n",
    "\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increased-management",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:46.019505Z",
     "iopub.status.busy": "2021-06-03T14:23:46.009386Z",
     "iopub.status.idle": "2021-06-03T14:23:46.045466Z",
     "shell.execute_reply": "2021-06-03T14:23:46.044593Z",
     "shell.execute_reply.started": "2021-06-03T12:12:02.147653Z"
    },
    "papermill": {
     "duration": 0.155346,
     "end_time": "2021-06-03T14:23:46.045719",
     "exception": false,
     "start_time": "2021-06-03T14:23:45.890373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_8 = [[]]*len(training_dataset)\n",
    "for i in range(len(training_dataset)):\n",
    "    train_8[i] = training_dataset.sample_labels[i][8]\n",
    "\n",
    "training_dataset.sample_labels = train_8\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cathedral-cambridge",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:46.328058Z",
     "iopub.status.busy": "2021-06-03T14:23:46.327017Z",
     "iopub.status.idle": "2021-06-03T14:23:46.366487Z",
     "shell.execute_reply": "2021-06-03T14:23:46.367399Z",
     "shell.execute_reply.started": "2021-06-03T12:12:02.213646Z"
    },
    "papermill": {
     "duration": 0.186655,
     "end_time": "2021-06-03T14:23:46.367664",
     "exception": false,
     "start_time": "2021-06-03T14:23:46.181009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset.sample_labels = torch.FloatTensor(training_dataset.sample_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-special",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:46.639799Z",
     "iopub.status.busy": "2021-06-03T14:23:46.638206Z",
     "iopub.status.idle": "2021-06-03T14:23:46.649115Z",
     "shell.execute_reply": "2021-06-03T14:23:46.650123Z",
     "shell.execute_reply.started": "2021-06-02T17:30:22.77095Z"
    },
    "papermill": {
     "duration": 0.150974,
     "end_time": "2021-06-03T14:23:46.650467",
     "exception": false,
     "start_time": "2021-06-03T14:23:46.499493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nidxs = []\\nfor i in range(len(validation_set)):\\n    if \\'8\\' in validation_set[i][4] :\\n        idxs.append(i)\\nprint(\"완료\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "idxs = []\n",
    "for i in range(len(validation_set)):\n",
    "    if '8' in validation_set[i][4] :\n",
    "        idxs.append(i)\n",
    "print(\"완료\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cosmetic-commitment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:46.918736Z",
     "iopub.status.busy": "2021-06-03T14:23:46.917754Z",
     "iopub.status.idle": "2021-06-03T14:23:46.923756Z",
     "shell.execute_reply": "2021-06-03T14:23:46.924607Z",
     "shell.execute_reply.started": "2021-06-02T17:30:22.782255Z"
    },
    "papermill": {
     "duration": 0.14143,
     "end_time": "2021-06-03T14:23:46.924842",
     "exception": false,
     "start_time": "2021-06-03T14:23:46.783412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntmp = list(validation_set)\\n\\nfor i in range(len(validation_set)) :\\n    validation_set[i] = list(validation_set[i])\\n    validation_set[i][4] = [\\'0\\']\\n    \\nfor i in idxs :\\n    validation_set[i][4] = [\"1\"]\\n\\nfor i in range(len(validation_set)) :\\n    validation_set[i] = tuple(validation_set[i])\\n\\nprint(validation_set[0][4])\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tmp = list(validation_set)\n",
    "\n",
    "for i in range(len(validation_set)) :\n",
    "    validation_set[i] = list(validation_set[i])\n",
    "    validation_set[i][4] = ['0']\n",
    "    \n",
    "for i in idxs :\n",
    "    validation_set[i][4] = [\"1\"]\n",
    "\n",
    "for i in range(len(validation_set)) :\n",
    "    validation_set[i] = tuple(validation_set[i])\n",
    "\n",
    "print(validation_set[0][4])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ignored-property",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:47.187286Z",
     "iopub.status.busy": "2021-06-03T14:23:47.186296Z",
     "iopub.status.idle": "2021-06-03T14:23:47.209189Z",
     "shell.execute_reply": "2021-06-03T14:23:47.210482Z",
     "shell.execute_reply.started": "2021-06-03T12:12:02.238117Z"
    },
    "papermill": {
     "duration": 0.15992,
     "end_time": "2021-06-03T14:23:47.210739",
     "exception": false,
     "start_time": "2021-06-03T14:23:47.050819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, pin_memory=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = Example_CNN_v1(num_classes=1, num_leads=2)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = Nadam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "#adagrad vs. adam\n",
    "\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "described-horizontal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:23:47.465311Z",
     "iopub.status.busy": "2021-06-03T14:23:47.464238Z",
     "iopub.status.idle": "2021-06-03T14:34:32.184409Z",
     "shell.execute_reply": "2021-06-03T14:34:32.185435Z",
     "shell.execute_reply.started": "2021-06-03T12:12:02.256193Z"
    },
    "papermill": {
     "duration": 644.848078,
     "end_time": "2021-06-03T14:34:32.185733",
     "exception": false,
     "start_time": "2021-06-03T14:23:47.337655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n",
      "training loss of epoch 1: 0.5954829398639595\n",
      "\n",
      "***** Epoch 2 *****\n",
      "training loss of epoch 2: 0.43833740060835263\n",
      "\n",
      "***** Epoch 3 *****\n",
      "training loss of epoch 3: 0.38529905416234295\n",
      "\n",
      "***** Epoch 4 *****\n",
      "training loss of epoch 4: 0.34743333690127504\n",
      "\n",
      "***** Epoch 5 *****\n",
      "training loss of epoch 5: 0.30217521075976034\n",
      "\n",
      "***** Epoch 6 *****\n",
      "training loss of epoch 6: 0.2554659780499595\n",
      "\n",
      "***** Epoch 7 *****\n",
      "training loss of epoch 7: 0.20634518938835975\n",
      "\n",
      "***** Epoch 8 *****\n",
      "training loss of epoch 8: 0.1726889009980123\n",
      "\n",
      "***** Epoch 9 *****\n",
      "training loss of epoch 9: 0.1540869129144932\n",
      "\n",
      "***** Epoch 10 *****\n",
      "training loss of epoch 10: 0.11235026998068054\n",
      "\n",
      "***** Epoch 11 *****\n",
      "training loss of epoch 11: 0.08639278305900387\n",
      "\n",
      "***** Epoch 12 *****\n",
      "training loss of epoch 12: 0.06599922728609502\n",
      "\n",
      "***** Epoch 13 *****\n",
      "training loss of epoch 13: 0.055967352855054754\n",
      "\n",
      "***** Epoch 14 *****\n",
      "training loss of epoch 14: 0.04746641277570402\n",
      "\n",
      "***** Epoch 15 *****\n",
      "training loss of epoch 15: 0.048244402597502435\n",
      "\n",
      "***** Epoch 16 *****\n",
      "training loss of epoch 16: 0.04414964685018012\n",
      "\n",
      "***** Epoch 17 *****\n",
      "training loss of epoch 17: 0.03848705406722175\n",
      "\n",
      "***** Epoch 18 *****\n",
      "training loss of epoch 18: 0.03146663130523599\n",
      "\n",
      "***** Epoch 19 *****\n",
      "training loss of epoch 19: 0.04353777838869259\n",
      "\n",
      "***** Epoch 20 *****\n",
      "training loss of epoch 20: 0.03383547747195142\n",
      "\n",
      "***** Epoch 21 *****\n",
      "training loss of epoch 21: 0.03103200376410248\n",
      "\n",
      "***** Epoch 22 *****\n",
      "training loss of epoch 22: 0.03466528617220404\n",
      "\n",
      "***** Epoch 23 *****\n",
      "training loss of epoch 23: 0.034357569065437646\n",
      "\n",
      "***** Epoch 24 *****\n",
      "training loss of epoch 24: 0.024086636767675935\n",
      "\n",
      "***** Epoch 25 *****\n",
      "training loss of epoch 25: 0.03162007496189228\n",
      "\n",
      "***** Epoch 26 *****\n",
      "training loss of epoch 26: 0.025778600928823395\n",
      "\n",
      "***** Epoch 27 *****\n",
      "training loss of epoch 27: 0.034869190902357475\n",
      "\n",
      "***** Epoch 28 *****\n",
      "training loss of epoch 28: 0.021220423417513595\n",
      "\n",
      "***** Epoch 29 *****\n",
      "training loss of epoch 29: 0.026798745688275817\n",
      "\n",
      "***** Epoch 30 *****\n",
      "training loss of epoch 30: 0.023026125433612675\n",
      "\n",
      "***** Epoch 31 *****\n",
      "training loss of epoch 31: 0.018017997325357516\n",
      "\n",
      "***** Epoch 32 *****\n",
      "training loss of epoch 32: 0.01387784871081\n",
      "\n",
      "***** Epoch 33 *****\n",
      "training loss of epoch 33: 0.03656231586966942\n",
      "\n",
      "***** Epoch 34 *****\n",
      "training loss of epoch 34: 0.01861434054054179\n",
      "\n",
      "***** Epoch 35 *****\n",
      "training loss of epoch 35: 0.024794247637972455\n",
      "\n",
      "***** Epoch 36 *****\n",
      "training loss of epoch 36: 0.021368656176949635\n",
      "\n",
      "***** Epoch 37 *****\n",
      "training loss of epoch 37: 0.01256691708238423\n",
      "\n",
      "***** Epoch 38 *****\n",
      "training loss of epoch 38: 0.01767119034397495\n",
      "\n",
      "***** Epoch 39 *****\n",
      "training loss of epoch 39: 0.024053453504931894\n",
      "\n",
      "***** Epoch 40 *****\n",
      "training loss of epoch 40: 0.021903983593758416\n",
      "\n",
      "***** Epoch 41 *****\n",
      "training loss of epoch 41: 0.013807316104124053\n",
      "\n",
      "***** Epoch 42 *****\n",
      "training loss of epoch 42: 0.014459972259260519\n",
      "\n",
      "***** Epoch 43 *****\n",
      "training loss of epoch 43: 0.020509308448362757\n",
      "\n",
      "***** Epoch 44 *****\n",
      "training loss of epoch 44: 0.01679729240787598\n",
      "\n",
      "***** Epoch 45 *****\n",
      "training loss of epoch 45: 0.020904777688007088\n",
      "\n",
      "***** Epoch 46 *****\n",
      "training loss of epoch 46: 0.014198352322344565\n",
      "\n",
      "***** Epoch 47 *****\n",
      "training loss of epoch 47: 0.01190762988563302\n",
      "\n",
      "***** Epoch 48 *****\n",
      "training loss of epoch 48: 0.0133929784166467\n",
      "\n",
      "***** Epoch 49 *****\n",
      "training loss of epoch 49: 0.017544162732363238\n",
      "\n",
      "***** Epoch 50 *****\n",
      "training loss of epoch 50: 0.014135919499112458\n",
      "\n",
      "***** Epoch 51 *****\n",
      "training loss of epoch 51: 0.011932960399444864\n",
      "\n",
      "***** Epoch 52 *****\n",
      "training loss of epoch 52: 0.016283723433970054\n",
      "\n",
      "***** Epoch 53 *****\n",
      "training loss of epoch 53: 0.02608048522400433\n",
      "\n",
      "***** Epoch 54 *****\n",
      "training loss of epoch 54: 0.02148309231944668\n",
      "\n",
      "***** Epoch 55 *****\n",
      "training loss of epoch 55: 0.03193493963570442\n",
      "\n",
      "***** Epoch 56 *****\n",
      "training loss of epoch 56: 0.007193711451752742\n",
      "\n",
      "***** Epoch 57 *****\n",
      "training loss of epoch 57: 0.003625666411262858\n",
      "\n",
      "***** Epoch 58 *****\n",
      "training loss of epoch 58: 0.013181278504699261\n",
      "\n",
      "***** Epoch 59 *****\n",
      "training loss of epoch 59: 0.03330815045686031\n",
      "\n",
      "***** Epoch 60 *****\n",
      "training loss of epoch 60: 0.013619175059542719\n",
      "\n",
      "***** Epoch 61 *****\n",
      "training loss of epoch 61: 0.004512597889451577\n",
      "\n",
      "***** Epoch 62 *****\n",
      "training loss of epoch 62: 0.019726176791483776\n",
      "\n",
      "***** Epoch 63 *****\n",
      "training loss of epoch 63: 0.014340160135267569\n",
      "\n",
      "***** Epoch 64 *****\n",
      "training loss of epoch 64: 0.00950515240495963\n",
      "\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'***** Epoch {epoch} *****')\n",
    "    epoch_training_loss_sum = 0.0\n",
    "    for i_batch, sample_batched in enumerate(training_loader):\n",
    "        b_recording = sample_batched[\"recording\"].to(device)\n",
    "        b_labels = sample_batched[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        b_out = model(b_recording)\n",
    "        loss = criterion(b_out, b_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_loss_sum += loss.item() * b_labels.shape[0]\n",
    "\n",
    "    epoch_training_loss = epoch_training_loss_sum / num_training\n",
    "    print(f'training loss of epoch {epoch}: {epoch_training_loss}\\n')\n",
    "\n",
    "    \n",
    "print(\"완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "environmental-adaptation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:32.393981Z",
     "iopub.status.busy": "2021-06-03T14:34:32.392793Z",
     "iopub.status.idle": "2021-06-03T14:34:32.398474Z",
     "shell.execute_reply": "2021-06-03T14:34:32.399028Z",
     "shell.execute_reply.started": "2021-06-02T17:33:05.58234Z"
    },
    "papermill": {
     "duration": 0.111252,
     "end_time": "2021-06-03T14:34:32.399175",
     "exception": false,
     "start_time": "2021-06-03T14:34:32.287923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix\\n\\nmodel.eval()\\n\\nvalidation_prediction_df = pd.DataFrame(columns=[\\'labels\\'])\\nvalidation_prediction_df.index.name = \\'id\\'\\nvalidation_true_labels_df = pd.DataFrame(columns=[\\'labels\\'])\\nvalidation_true_labels_df.index.name = \\'id\\'\\n\\nwith torch.no_grad():\\n    for idx in range(len(validation_set)):\\n        validation_sample = validation_set[idx]\\n        _, _, _, recording, labels = validation_sample\\n        \\n        sample_prediction = model(torch.tensor(recording).unsqueeze(0).to(device)) > 0.5\\n        \\n        if (sample_prediction.cpu()==True) :\\n            rlt = 1\\n        else :\\n            rlt = 0\\n        validation_prediction_df.loc[idx] = [rlt]\\n        validation_true_labels_df.loc[idx] = int(labels[0])\\n        \\nprint(\"완료\")\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "\n",
    "validation_prediction_df = pd.DataFrame(columns=['labels'])\n",
    "validation_prediction_df.index.name = 'id'\n",
    "validation_true_labels_df = pd.DataFrame(columns=['labels'])\n",
    "validation_true_labels_df.index.name = 'id'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(validation_set)):\n",
    "        validation_sample = validation_set[idx]\n",
    "        _, _, _, recording, labels = validation_sample\n",
    "        \n",
    "        sample_prediction = model(torch.tensor(recording).unsqueeze(0).to(device)) > 0.5\n",
    "        \n",
    "        if (sample_prediction.cpu()==True) :\n",
    "            rlt = 1\n",
    "        else :\n",
    "            rlt = 0\n",
    "        validation_prediction_df.loc[idx] = [rlt]\n",
    "        validation_true_labels_df.loc[idx] = int(labels[0])\n",
    "        \n",
    "print(\"완료\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "creative-handy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:32.599120Z",
     "iopub.status.busy": "2021-06-03T14:34:32.598341Z",
     "iopub.status.idle": "2021-06-03T14:34:32.605374Z",
     "shell.execute_reply": "2021-06-03T14:34:32.605937Z",
     "shell.execute_reply.started": "2021-06-02T17:34:44.056023Z"
    },
    "papermill": {
     "duration": 0.108687,
     "end_time": "2021-06-03T14:34:32.606088",
     "exception": false,
     "start_time": "2021-06-03T14:34:32.497401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncnt = len(validation_set)\\ncorrect = 0\\nfor i in range(len(validation_set)) :\\n    m = validation_prediction_df[\"labels\"].iloc[i] - validation_true_labels_df[\"labels\"].iloc[i]\\n    if (m==0) :\\n        correct+=1\\n        \\nprint(\"accuracy : %f\" % (correct/cnt))\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "cnt = len(validation_set)\n",
    "correct = 0\n",
    "for i in range(len(validation_set)) :\n",
    "    m = validation_prediction_df[\"labels\"].iloc[i] - validation_true_labels_df[\"labels\"].iloc[i]\n",
    "    if (m==0) :\n",
    "        correct+=1\n",
    "        \n",
    "print(\"accuracy : %f\" % (correct/cnt))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boxed-landing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:32.807429Z",
     "iopub.status.busy": "2021-06-03T14:34:32.806482Z",
     "iopub.status.idle": "2021-06-03T14:34:32.810738Z",
     "shell.execute_reply": "2021-06-03T14:34:32.811243Z",
     "shell.execute_reply.started": "2021-06-02T17:09:08.675052Z"
    },
    "papermill": {
     "duration": 0.107853,
     "end_time": "2021-06-03T14:34:32.811389",
     "exception": false,
     "start_time": "2021-06-03T14:34:32.703536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sklearn.metrics\\n\\n\\nfor i in range(len(validation_set)) :\\n    validation_prediction_df[\"labels\"].iloc[i] = bin(validation_prediction_df[\"labels\"].iloc[i])\\n    validation_true_labels_df[\"labels\"].iloc[i] = bin(validation_true_labels_df[\"labels\"].iloc[i])\\n\\n    \\nprint(sklearn.metrics.confusion_matrix(validation_true_labels_df[\"labels\"], validation_prediction_df[\"labels\"]))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "for i in range(len(validation_set)) :\n",
    "    validation_prediction_df[\"labels\"].iloc[i] = bin(validation_prediction_df[\"labels\"].iloc[i])\n",
    "    validation_true_labels_df[\"labels\"].iloc[i] = bin(validation_true_labels_df[\"labels\"].iloc[i])\n",
    "\n",
    "    \n",
    "print(sklearn.metrics.confusion_matrix(validation_true_labels_df[\"labels\"], validation_prediction_df[\"labels\"]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alien-hobby",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:33.014121Z",
     "iopub.status.busy": "2021-06-03T14:34:33.013245Z",
     "iopub.status.idle": "2021-06-03T14:34:33.019727Z",
     "shell.execute_reply": "2021-06-03T14:34:33.019173Z"
    },
    "papermill": {
     "duration": 0.110085,
     "end_time": "2021-06-03T14:34:33.019927",
     "exception": false,
     "start_time": "2021-06-03T14:34:32.909842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.eval()\\n\\nvalidation_prediction_df = pd.DataFrame(columns=[\\'labels\\'])\\nvalidation_prediction_df.index.name = \\'id\\'\\nvalidation_true_labels_df = pd.DataFrame(columns=[\\'labels\\'])\\nvalidation_true_labels_df.index.name = \\'id\\'\\n\\nwith torch.no_grad():\\n    for idx in range(len(validation_set)):\\n        validation_sample = validation_set[idx]\\n        _, _, _, recording, labels = validation_sample\\n        out = model(torch.tensor(recording).unsqueeze(0).to(device)) # unsqueeze는 batch dimension을 추가해주기 위함\\n        sample_prediction = torch.nn.functional.sigmoid(out).squeeze() > 0.5 # Use 0.5 as a threshold / squeeze는 batch dimension을 제거해주기 위함\\n        indices_of_1s = np.where(sample_prediction.cpu())[0]\\n        str_indices_of_1s = \\' \\'.join(map(str, indices_of_1s))\\n        validation_prediction_df.loc[idx] = [str_indices_of_1s]\\n        \\n        str_true_labels = \\' \\'.join(labels)\\n        validation_true_labels_df.loc[idx] = [str_true_labels]\\n\\n        \\n\\nprint(\"완료\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model.eval()\n",
    "\n",
    "validation_prediction_df = pd.DataFrame(columns=['labels'])\n",
    "validation_prediction_df.index.name = 'id'\n",
    "validation_true_labels_df = pd.DataFrame(columns=['labels'])\n",
    "validation_true_labels_df.index.name = 'id'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(validation_set)):\n",
    "        validation_sample = validation_set[idx]\n",
    "        _, _, _, recording, labels = validation_sample\n",
    "        out = model(torch.tensor(recording).unsqueeze(0).to(device)) # unsqueeze는 batch dimension을 추가해주기 위함\n",
    "        sample_prediction = torch.nn.functional.sigmoid(out).squeeze() > 0.5 # Use 0.5 as a threshold / squeeze는 batch dimension을 제거해주기 위함\n",
    "        indices_of_1s = np.where(sample_prediction.cpu())[0]\n",
    "        str_indices_of_1s = ' '.join(map(str, indices_of_1s))\n",
    "        validation_prediction_df.loc[idx] = [str_indices_of_1s]\n",
    "        \n",
    "        str_true_labels = ' '.join(labels)\n",
    "        validation_true_labels_df.loc[idx] = [str_true_labels]\n",
    "\n",
    "        \n",
    "\n",
    "print(\"완료\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "accredited-rochester",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:33.222172Z",
     "iopub.status.busy": "2021-06-03T14:34:33.221423Z",
     "iopub.status.idle": "2021-06-03T14:34:33.229149Z",
     "shell.execute_reply": "2021-06-03T14:34:33.228496Z"
    },
    "papermill": {
     "duration": 0.111009,
     "end_time": "2021-06-03T14:34:33.229293",
     "exception": false,
     "start_time": "2021-06-03T14:34:33.118284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(validation_prediction_df)) :\\n    \\n    tmp = validation_prediction_df[\\'labels\\'].iloc[i]\\n    \\n    if (\"8\" in tmp) :\\n        if (len(tmp)>=2) :\\n            validation_prediction_df[\\'labels\\'].iloc[i]=\"8\"\\n    \\'\\'\\'\\n    if (\"2\" in tmp) :\\n        if (\"3\" not in tmp) :\\n             validation_prediction_df[\\'labels\\'].iloc[i]=tmp.replace(\"2\", \"2 3\", 1)\\n    \\'\\'\\' \\n\\nprint(validation_prediction_df.head())\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(len(validation_prediction_df)) :\n",
    "    \n",
    "    tmp = validation_prediction_df['labels'].iloc[i]\n",
    "    \n",
    "    if (\"8\" in tmp) :\n",
    "        if (len(tmp)>=2) :\n",
    "            validation_prediction_df['labels'].iloc[i]=\"8\"\n",
    "    '''\n",
    "    if (\"2\" in tmp) :\n",
    "        if (\"3\" not in tmp) :\n",
    "             validation_prediction_df['labels'].iloc[i]=tmp.replace(\"2\", \"2 3\", 1)\n",
    "    ''' \n",
    "\n",
    "print(validation_prediction_df.head())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "endangered-armor",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:33.434829Z",
     "iopub.status.busy": "2021-06-03T14:34:33.434150Z",
     "iopub.status.idle": "2021-06-03T14:34:33.441141Z",
     "shell.execute_reply": "2021-06-03T14:34:33.440602Z"
    },
    "papermill": {
     "duration": 0.111783,
     "end_time": "2021-06-03T14:34:33.441278",
     "exception": false,
     "start_time": "2021-06-03T14:34:33.329495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import MultiLabelBinarizer\\nfrom sklearn.metrics import f1_score\\n\\n\\nmlb = MultiLabelBinarizer(classes=['0','1','2','3','4','5','6','7','8','9','10','11'])\\nmlb.fit(map(str.split, validation_true_labels_df['labels'].values))\\n\\nmacro_f1_validation = f1_score(mlb.transform(map(str.split, validation_true_labels_df['labels'].values)), mlb.transform(map(str.split, validation_prediction_df['labels'].values)), average='macro')\\nprint(f'macro f1 score on validation set: {macro_f1_validation}')\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=['0','1','2','3','4','5','6','7','8','9','10','11'])\n",
    "mlb.fit(map(str.split, validation_true_labels_df['labels'].values))\n",
    "\n",
    "macro_f1_validation = f1_score(mlb.transform(map(str.split, validation_true_labels_df['labels'].values)), mlb.transform(map(str.split, validation_prediction_df['labels'].values)), average='macro')\n",
    "print(f'macro f1 score on validation set: {macro_f1_validation}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bottom-panic",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:34:33.646020Z",
     "iopub.status.busy": "2021-06-03T14:34:33.645132Z",
     "iopub.status.idle": "2021-06-03T14:36:09.011240Z",
     "shell.execute_reply": "2021-06-03T14:36:09.011929Z",
     "shell.execute_reply.started": "2021-06-03T12:13:33.053387Z"
    },
    "papermill": {
     "duration": 95.471226,
     "end_time": "2021-06-03T14:36:09.012121",
     "exception": false,
     "start_time": "2021-06-03T14:34:33.540895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 7389\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = sorted(read_files(test_dir, is_training=False), key=lambda sample:sample[0])\n",
    "num_test = len(test_set)\n",
    "print(f'Number of test samples: {num_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sublime-financing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:36:09.270809Z",
     "iopub.status.busy": "2021-06-03T14:36:09.270073Z",
     "iopub.status.idle": "2021-06-03T14:36:47.129491Z",
     "shell.execute_reply": "2021-06-03T14:36:47.130385Z",
     "shell.execute_reply.started": "2021-06-03T12:14:28.984337Z"
    },
    "papermill": {
     "duration": 37.982176,
     "end_time": "2021-06-03T14:36:47.130659",
     "exception": false,
     "start_time": "2021-06-03T14:36:09.148483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   labels\n",
      "id       \n",
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       1\n",
      "5       1\n",
      "6       1\n",
      "7       1\n",
      "8       1\n",
      "9       1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_prediction_df = pd.DataFrame(columns=['labels'])\n",
    "test_prediction_df.index.name = 'id'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_set)):\n",
    "        test_sample = test_set[idx]\n",
    "        _, _, _, recording = test_sample\n",
    "        \n",
    "        sample_prediction = model(torch.tensor(recording).unsqueeze(0).to(device)) > 0.5\n",
    "        try :\n",
    "            if (sample_prediction.cpu()==True) :\n",
    "                rlt = 1\n",
    "            else :\n",
    "                rlt = 0\n",
    "        except : \n",
    "            print(sample_prediction)\n",
    "            rlt=0\n",
    "        test_prediction_df.loc[idx] = [rlt]\n",
    "print(test_prediction_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "brave-passport",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:36:47.374479Z",
     "iopub.status.busy": "2021-06-03T14:36:47.359179Z",
     "iopub.status.idle": "2021-06-03T14:36:47.448204Z",
     "shell.execute_reply": "2021-06-03T14:36:47.447350Z",
     "shell.execute_reply.started": "2021-06-03T12:14:54.984012Z"
    },
    "papermill": {
     "duration": 0.21332,
     "end_time": "2021-06-03T14:36:47.448431",
     "exception": false,
     "start_time": "2021-06-03T14:36:47.235111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 10]\n"
     ]
    }
   ],
   "source": [
    "unnormal_idx = []\n",
    "for i in range(len(test_set)) :\n",
    "    if (test_prediction_df[\"labels\"].iloc[i] == 0) :\n",
    "        unnormal_idx.append(i)\n",
    "        \n",
    "print(unnormal_idx[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "multiple-aerospace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:36:47.665313Z",
     "iopub.status.busy": "2021-06-03T14:36:47.663821Z",
     "iopub.status.idle": "2021-06-03T14:36:47.669713Z",
     "shell.execute_reply": "2021-06-03T14:36:47.669161Z",
     "shell.execute_reply.started": "2021-06-03T12:14:55.070361Z"
    },
    "papermill": {
     "duration": 0.11658,
     "end_time": "2021-06-03T14:36:47.669845",
     "exception": false,
     "start_time": "2021-06-03T14:36:47.553265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 85.0, 'F', array([[ 0.015,  0.015,  0.015, ..., -0.03 , -0.03 , -0.03 ],\n",
      "       [ 0.025,  0.025,  0.025, ..., -0.15 , -0.15 , -0.15 ]],\n",
      "      dtype=float32))\n",
      "(1, 51.0, 'M', array([[-0.025, -0.025, -0.025, ..., -0.035, -0.035, -0.035],\n",
      "       [ 0.025,  0.025,  0.025, ..., -0.095, -0.095, -0.095]],\n",
      "      dtype=float32))\n",
      "(2, 68.0, 'F', array([[-0.039, -0.039, -0.039, ...,  0.039,  0.039,  0.043],\n",
      "       [-0.029, -0.029, -0.029, ..., -0.019, -0.019, -0.014]],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "test_set_unnormal = []\n",
    "\n",
    "for i in unnormal_idx :\n",
    "    test_set_unnormal.append(test_set[i])\n",
    "\n",
    "\n",
    "print(test_set_unnormal[0])\n",
    "print(test_set_unnormal[1])\n",
    "print(test_set_unnormal[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "offensive-michigan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:36:47.889306Z",
     "iopub.status.busy": "2021-06-03T14:36:47.888156Z",
     "iopub.status.idle": "2021-06-03T14:37:44.050130Z",
     "shell.execute_reply": "2021-06-03T14:37:44.049555Z",
     "shell.execute_reply.started": "2021-06-03T12:14:55.080992Z"
    },
    "papermill": {
     "duration": 56.276416,
     "end_time": "2021-06-03T14:37:44.050330",
     "exception": false,
     "start_time": "2021-06-03T14:36:47.773914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "model3.eval()\n",
    "\n",
    "test_prediction_df_3 = pd.DataFrame(columns=['labels'])\n",
    "test_prediction_df_3.index.name = 'id'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_set)):\n",
    "        test_sample = test_set[idx]\n",
    "        _, _, _, recording = test_sample\n",
    "        out = model3(torch.tensor(recording).unsqueeze(0).to(device)) # unsqueeze는 batch dimension을 추가해주기 위함\n",
    "        sample_prediction = torch.nn.functional.sigmoid(out).squeeze() > 0.5 # Use 0.5 as a threshold / squeeze는 batch dimension을 제거해주기 위함\n",
    "        indices_of_1s = np.where(sample_prediction.cpu())[0]\n",
    "        str_indices_of_1s = ' '.join(map(str, indices_of_1s))\n",
    "        test_prediction_df_3.loc[idx] = [str_indices_of_1s]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "detected-ground",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:37:44.271195Z",
     "iopub.status.busy": "2021-06-03T14:37:44.270017Z",
     "iopub.status.idle": "2021-06-03T14:38:00.656887Z",
     "shell.execute_reply": "2021-06-03T14:38:00.655634Z",
     "shell.execute_reply.started": "2021-06-03T12:15:33.346469Z"
    },
    "papermill": {
     "duration": 16.502098,
     "end_time": "2021-06-03T14:38:00.657124",
     "exception": false,
     "start_time": "2021-06-03T14:37:44.155026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.eval()\n",
    "\n",
    "test_prediction_df_2 = pd.DataFrame(columns=['labels'])\n",
    "test_prediction_df_2.index.name = 'id'\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(test_set_unnormal)):\n",
    "        test_sample = test_set_unnormal[idx]\n",
    "        _, _, _, recording = test_sample\n",
    "        out = model2(torch.tensor(recording).unsqueeze(0).to(device)) # unsqueeze는 batch dimension을 추가해주기 위함\n",
    "        sample_prediction = torch.nn.functional.sigmoid(out).squeeze() > 0.5 # Use 0.5 as a threshold / squeeze는 batch dimension을 제거해주기 위함\n",
    "        indices_of_1s = np.where(sample_prediction.cpu())[0]\n",
    "        str_indices_of_1s = ' '.join(map(str, indices_of_1s))\n",
    "        test_prediction_df_2.loc[idx] = [str_indices_of_1s]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "funky-religion",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:38:00.963385Z",
     "iopub.status.busy": "2021-06-03T14:38:00.955289Z",
     "iopub.status.idle": "2021-06-03T14:38:02.501220Z",
     "shell.execute_reply": "2021-06-03T14:38:02.500645Z",
     "shell.execute_reply.started": "2021-06-03T12:15:45.725034Z"
    },
    "papermill": {
     "duration": 1.657461,
     "end_time": "2021-06-03T14:38:02.501413",
     "exception": false,
     "start_time": "2021-06-03T14:38:00.843952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for i in range(len(test_prediction_df)) :\n",
    "    if (test_prediction_df[\"labels\"].iloc[i] == 1) :\n",
    "        test_prediction_df[\"labels\"].iloc[i] = \"8\"\n",
    "    else :\n",
    "        test_prediction_df[\"labels\"].iloc[i] = test_prediction_df_2[\"labels\"].iloc[n]\n",
    "        n+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "indoor-intake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:38:02.723117Z",
     "iopub.status.busy": "2021-06-03T14:38:02.721959Z",
     "iopub.status.idle": "2021-06-03T14:38:02.820249Z",
     "shell.execute_reply": "2021-06-03T14:38:02.819718Z",
     "shell.execute_reply.started": "2021-06-03T12:15:46.644406Z"
    },
    "papermill": {
     "duration": 0.215835,
     "end_time": "2021-06-03T14:38:02.820403",
     "exception": false,
     "start_time": "2021-06-03T14:38:02.604568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-428c2b34ca57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_prediction_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_prediction_df_3\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtest_prediction_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_prediction_df_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         raise ValueError(\n\u001b[0;32m-> 1330\u001b[0;31m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(test_prediction_df)) :\n",
    "    \n",
    "    tmp = test_prediction_df['labels'].iloc[i]\n",
    "    \n",
    "    if ((tmp == \"\") & (test_prediction_df_3 != \"\")) :\n",
    "        test_prediction_df[\"labels\"].iloc[i] = test_prediction_df_3[\"labels\"].iloc[i]\n",
    "    \n",
    "    if ((tmp == \"8\") & (\"8\" in test_prediction_df_3[\"labels\"].iloc[i])) :\n",
    "        test_prediction_df[\"labels\"].iloc[i] = test_prediction_df_3[\"labels\"].iloc[i]\n",
    "    \n",
    "    if (\"2\" in tmp) :\n",
    "        if (\"3\" not in tmp) :\n",
    "             test_prediction_df['labels'].iloc[i] = tmp.replace(\"2\", \"2 3\", 1)\n",
    "    \n",
    "    if ((tmp == \"\") & (test_prediction_df_3 == \"\")) :\n",
    "        test_prediction_df[\"labels\"].iloc[i] = \"6\"\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "therapeutic-thinking",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-03T14:38:03.033465Z",
     "iopub.status.busy": "2021-06-03T14:38:03.032703Z",
     "iopub.status.idle": "2021-06-03T14:38:03.229068Z",
     "shell.execute_reply": "2021-06-03T14:38:03.228315Z"
    },
    "papermill": {
     "duration": 0.303937,
     "end_time": "2021-06-03T14:38:03.229216",
     "exception": false,
     "start_time": "2021-06-03T14:38:02.925279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction_df.to_csv('my_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2467.628293,
   "end_time": "2021-06-03T14:38:05.349965",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-03T13:56:57.721672",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
