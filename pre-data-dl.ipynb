{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disciplinary-speaking",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-31T10:28:50.304795Z",
     "iopub.status.busy": "2021-05-31T10:28:50.296977Z",
     "iopub.status.idle": "2021-05-31T10:29:04.897315Z",
     "shell.execute_reply": "2021-05-31T10:29:04.896124Z",
     "shell.execute_reply.started": "2021-05-31T09:26:54.757212Z"
    },
    "papermill": {
     "duration": 14.615677,
     "end_time": "2021-05-31T10:29:04.897532",
     "exception": false,
     "start_time": "2021-05-31T10:28:50.281855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "\n",
    "class Dataset_ECG_pytorch(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        Build ECG dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, list_id, list_age, list_sex, list_recording, list_labels_oh=None, num_classes=12):\n",
    "        \"\"\"\n",
    "            dataset을 읽어들여 id, age, sex, recording, labels를 저장한 list를 만들어 줍니다.\n",
    "        \"\"\"\n",
    "        self.sample_id = torch.tensor(list_id)\n",
    "        self.sample_age = torch.tensor(list_age)\n",
    "        self.sample_sex = torch.tensor(list_sex)\n",
    "        self.sample_recording = torch.tensor(list_recording)\n",
    "\n",
    "        length = len(list_id)\n",
    "        assert length==len(self.sample_id)\n",
    "        assert length==len(self.sample_age)\n",
    "        assert length==len(self.sample_sex)\n",
    "        assert length==len(self.sample_recording)\n",
    "\n",
    "        if not list_labels_oh is None:\n",
    "            self.train = True\n",
    "            self.sample_labels = torch.tensor(list_labels_oh)\n",
    "            assert length==len(self.sample_labels)\n",
    "        \n",
    "        self.num_samples = length\n",
    "        \n",
    "        print(f'Loaded {self.num_samples} samples...')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        result = {\n",
    "            \"id\": self.sample_id[idx],\n",
    "            \"age\": self.sample_age[idx],\n",
    "            \"sex\": self.sample_sex[idx],\n",
    "            \"recording\": self.sample_recording[idx],\n",
    "        }\n",
    "        if self.train:\n",
    "            result['labels'] = self.sample_labels[idx]\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "base_dir = '../input/project-3/'\n",
    "with open(base_dir+'train_data_torch.pkl', 'rb') as f:\n",
    "    training_dataset = pickle.load(f)\n",
    "with open(base_dir+'test_data_torch.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)\n",
    "\n",
    "print(\"완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broadband-edmonton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:29:04.926100Z",
     "iopub.status.busy": "2021-05-31T10:29:04.924843Z",
     "iopub.status.idle": "2021-05-31T10:29:04.928814Z",
     "shell.execute_reply": "2021-05-31T10:29:04.928185Z",
     "shell.execute_reply.started": "2021-05-31T09:27:06.472426Z"
    },
    "papermill": {
     "duration": 0.023962,
     "end_time": "2021-05-31T10:29:04.928958",
     "exception": false,
     "start_time": "2021-05-31T10:29:04.904996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "#num_classes -> label / num_leads -> recording1,2 / out_channel -> recording shape\n",
    "class Example_CNN_v1(torch.nn.Module):\n",
    "    def __init__(self, num_classes=12, num_leads=2):\n",
    "        super(Example_CNN_v1, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_leads = num_leads\n",
    "        self.conv1 = torch.nn.Conv1d(in_channels=self.num_leads, out_channels=32, kernel_size=15, stride=3, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU() #1498\n",
    "        self.conv2 = torch.nn.Conv1d(in_channels=32, out_channels=64, kernel_size=13, stride=3, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU() #497\n",
    "        self.conv3 = torch.nn.Conv1d(in_channels=64, out_channels=128, kernel_size=11, stride=3, padding=1)\n",
    "        self.relu3 = torch.nn.ReLU() #164\n",
    "        self.conv4 = torch.nn.Conv1d(in_channels=128, out_channels=128, kernel_size=10, stride=2)\n",
    "        self.relu4 = torch.nn.ReLU() #78\n",
    "        self.conv5 = torch.nn.Conv1d(in_channels=128, out_channels=64, kernel_size=9, stride=1)\n",
    "        self.relu5 = torch.nn.ReLU() #70\n",
    "        self.conv6 = torch.nn.Conv1d(in_channels=64, out_channels=32, kernel_size=7, stride=1)\n",
    "        self.relu6 = torch.nn.ReLU() #64\n",
    "        self.fc1 = torch.nn.Linear(32*63, 128)\n",
    "        self.relu7 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(128, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 이 모델은 recording만을 input으로 받습니다. feature를 추가적으로 사용하도록 할 수도 있습니다.\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        #print(x.size())\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu7(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "print(\"완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "answering-philosophy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:29:04.989721Z",
     "iopub.status.busy": "2021-05-31T10:29:04.989084Z",
     "iopub.status.idle": "2021-05-31T10:29:04.993342Z",
     "shell.execute_reply": "2021-05-31T10:29:04.992929Z",
     "shell.execute_reply.started": "2021-05-31T09:27:06.490936Z"
    },
    "papermill": {
     "duration": 0.05663,
     "end_time": "2021-05-31T10:29:04.993469",
     "exception": false,
     "start_time": "2021-05-31T10:29:04.936839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "swedish-steps",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:29:05.021788Z",
     "iopub.status.busy": "2021-05-31T10:29:05.012753Z",
     "iopub.status.idle": "2021-05-31T10:29:09.124091Z",
     "shell.execute_reply": "2021-05-31T10:29:09.123274Z",
     "shell.execute_reply.started": "2021-05-31T09:31:23.089819Z"
    },
    "papermill": {
     "duration": 4.123538,
     "end_time": "2021-05-31T10:29:09.124218",
     "exception": false,
     "start_time": "2021-05-31T10:29:05.000680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, pin_memory=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "num_training = len(training_dataset)\n",
    "\n",
    "\n",
    "model = Example_CNN_v1(num_classes=12, num_leads=2)\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss() # for multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = Nadam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rapid-rough",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:29:09.147578Z",
     "iopub.status.busy": "2021-05-31T10:29:09.146949Z",
     "iopub.status.idle": "2021-05-31T10:32:37.949784Z",
     "shell.execute_reply": "2021-05-31T10:32:37.949075Z",
     "shell.execute_reply.started": "2021-05-31T09:31:25.798394Z"
    },
    "papermill": {
     "duration": 208.818104,
     "end_time": "2021-05-31T10:32:37.949935",
     "exception": false,
     "start_time": "2021-05-31T10:29:09.131831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n",
      "training loss of epoch 1: 0.2801238125856782\n",
      "\n",
      "***** Epoch 2 *****\n",
      "training loss of epoch 2: 0.2615826489861846\n",
      "\n",
      "***** Epoch 3 *****\n",
      "training loss of epoch 3: 0.24961335177709976\n",
      "\n",
      "***** Epoch 4 *****\n",
      "training loss of epoch 4: 0.21114555345943214\n",
      "\n",
      "***** Epoch 5 *****\n",
      "training loss of epoch 5: 0.1937403153335703\n",
      "\n",
      "***** Epoch 6 *****\n",
      "training loss of epoch 6: 0.18606483509410007\n",
      "\n",
      "***** Epoch 7 *****\n",
      "training loss of epoch 7: 0.17950705251308027\n",
      "\n",
      "***** Epoch 8 *****\n",
      "training loss of epoch 8: 0.17360426626700848\n",
      "\n",
      "***** Epoch 9 *****\n",
      "training loss of epoch 9: 0.16761733252611752\n",
      "\n",
      "***** Epoch 10 *****\n",
      "training loss of epoch 10: 0.1627390944483676\n",
      "\n",
      "***** Epoch 11 *****\n",
      "training loss of epoch 11: 0.1561425787451216\n",
      "\n",
      "***** Epoch 12 *****\n",
      "training loss of epoch 12: 0.14930602767902837\n",
      "\n",
      "***** Epoch 13 *****\n",
      "training loss of epoch 13: 0.141980919724029\n",
      "\n",
      "***** Epoch 14 *****\n",
      "training loss of epoch 14: 0.1338491038732074\n",
      "\n",
      "***** Epoch 15 *****\n",
      "training loss of epoch 15: 0.12633747654937344\n",
      "\n",
      "***** Epoch 16 *****\n",
      "training loss of epoch 16: 0.11892759999290943\n",
      "\n",
      "***** Epoch 17 *****\n",
      "training loss of epoch 17: 0.11198764794193752\n",
      "\n",
      "***** Epoch 18 *****\n",
      "training loss of epoch 18: 0.10546883189743965\n",
      "\n",
      "***** Epoch 19 *****\n",
      "training loss of epoch 19: 0.09877691016162705\n",
      "\n",
      "***** Epoch 20 *****\n",
      "training loss of epoch 20: 0.09156683969148342\n",
      "\n",
      "완료\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'***** Epoch {epoch} *****')\n",
    "    epoch_training_loss_sum = 0.0\n",
    "    for i_batch, sample_batched in enumerate(training_loader):\n",
    "        b_recording = sample_batched[\"recording\"].to(device)\n",
    "        b_labels = sample_batched[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        b_out = model(b_recording)\n",
    "        loss = criterion(b_out, b_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_loss_sum += loss.item() * b_labels.shape[0]\n",
    "\n",
    "    epoch_training_loss = epoch_training_loss_sum / num_training\n",
    "    print(f'training loss of epoch {epoch}: {epoch_training_loss}\\n')\n",
    "\n",
    "print(\"완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entitled-encyclopedia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:32:37.993534Z",
     "iopub.status.busy": "2021-05-31T10:32:37.992711Z",
     "iopub.status.idle": "2021-05-31T10:33:06.929889Z",
     "shell.execute_reply": "2021-05-31T10:33:06.928945Z",
     "shell.execute_reply.started": "2021-05-31T10:27:44.331649Z"
    },
    "papermill": {
     "duration": 28.966248,
     "end_time": "2021-05-31T10:33:06.930044",
     "exception": false,
     "start_time": "2021-05-31T10:32:37.963796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_prediction_df = pd.DataFrame(columns=['labels'])\n",
    "\n",
    "\n",
    "test_len = len(test_dataset) # 바꿔야\n",
    "with torch.no_grad():\n",
    "    for idx in range(test_len):\n",
    "        recording = test_dataset.sample_recording[idx]\n",
    "        out = model(recording.unsqueeze(0).to(device)) # unsqueeze는 batch dimension을 추가해주기 위함\n",
    "        sample_prediction = out.squeeze() > 0.5 # Use 0.5 as a threshold / squeeze는 batch dimension을 제거해주기 위함\n",
    "        indices_of_1s = np.where(sample_prediction.cpu())[0]\n",
    "        str_indices_of_1s = ' '.join(map(str, indices_of_1s))\n",
    "        test_prediction_df.loc[idx] = [str_indices_of_1s]\n",
    "\n",
    "test_prediction_df.index = test_dataset.sample_id.tolist()\n",
    "test_prediction_df.index.name = 'id'\n",
    "test_prediction_df.sort_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "descending-interference",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:33:06.962343Z",
     "iopub.status.busy": "2021-05-31T10:33:06.961749Z",
     "iopub.status.idle": "2021-05-31T10:33:06.964947Z",
     "shell.execute_reply": "2021-05-31T10:33:06.965540Z",
     "shell.execute_reply.started": "2021-05-31T10:28:13.102168Z"
    },
    "papermill": {
     "duration": 0.022656,
     "end_time": "2021-05-31T10:33:06.965724",
     "exception": false,
     "start_time": "2021-05-31T10:33:06.943068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   labels\n",
      "id       \n",
      "0       9\n",
      "1     3 8\n",
      "2       8\n",
      "3   2 3 8\n",
      "4       8\n",
      "7389\n"
     ]
    }
   ],
   "source": [
    "print(test_prediction_df.head())\n",
    "\n",
    "print(len(test_prediction_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "grateful-revision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T10:33:06.995787Z",
     "iopub.status.busy": "2021-05-31T10:33:06.995259Z",
     "iopub.status.idle": "2021-05-31T10:33:07.127399Z",
     "shell.execute_reply": "2021-05-31T10:33:07.126966Z"
    },
    "papermill": {
     "duration": 0.147868,
     "end_time": "2021-05-31T10:33:07.127532",
     "exception": false,
     "start_time": "2021-05-31T10:33:06.979664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_prediction_df.to_csv('my_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 264.715071,
   "end_time": "2021-05-31T10:33:08.513367",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-31T10:28:43.798296",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
